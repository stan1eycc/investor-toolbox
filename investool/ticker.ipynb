{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "XXX License\n",
    "Copyright (C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ISIN to Bloomberg ticker from Google\n",
    "\n",
    "def isin2bbg(isin_ticker):\n",
    "    url = 'https://www.google.com.tw/search'  \n",
    "    keys = '+fundinfo+bloomberg'\n",
    "    key_url = 'product'\n",
    "        \n",
    "    # Search on Google\n",
    "    r = requests.get( url, params = {'q': isin_ticker + keys } )\n",
    "    #print(r.url)\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:  \n",
    "      \n",
    "        soup = bs(r.text, 'html.parser')\n",
    "        items = soup.select('div.g')\n",
    "\n",
    "        if len(items) < 1:\n",
    "            return -1\n",
    "        \n",
    "        for item in items:\n",
    "            s = item.find('a').get('href')\n",
    "            link = parse_qs(urlparse(s)[4])['q'][0]            \n",
    "            parsed_link = urlparse(link)\n",
    "            \n",
    "            if key_url in parsed_link[2]:\n",
    "                s = item.find('span', class_='st').text\n",
    "                i = s.find(\"Bloomberg Code,\")\n",
    "                \n",
    "                return s[i+16:i+23] + ':' + s[i+24:i+26]\n",
    "            \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Bloomberg to ISIN from Google\n",
    "\n",
    "def bbg2isin(bbg_ticker):\n",
    "    url = 'https://www.google.com.tw/search'  \n",
    "    keys = '\"+fundinfo+isin'\n",
    "    key_url = 'product'\n",
    "        \n",
    "    # Search on Google\n",
    "    r = requests.get( url, params = {'q': '\"' + bbg_ticker + keys } )\n",
    "    #print(r.url)\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:\n",
    "        \n",
    "        soup = bs(r.text, 'html.parser')\n",
    "        items = soup.select('div.g')\n",
    "        \n",
    "        if len(items) < 1:\n",
    "            return -1\n",
    "        \n",
    "        for item in items:           \n",
    "            s = item.find('a').get('href')\n",
    "            link = parse_qs(urlparse(s)[4])['q'][0]\n",
    "            parsed_link = urlparse(link)\n",
    "            \n",
    "            if key_url in parsed_link[2]:\n",
    "                s = item.find('span', class_='st').text\n",
    "                i = s.find(\"ISIN,\")                \n",
    "                \n",
    "                return s[i+6:i+18]\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ISIN to Morningstar ticker\n",
    "\n",
    "def isin2morningstar(isin_ticker):\n",
    "    url = 'https://www.google.com.tw/search'  \n",
    "    keys = '+morningstar'\n",
    "        \n",
    "    # Search on Google\n",
    "    r = requests.get( url, params = {'q': isin_ticker + keys } )\n",
    "    #print(r.url)\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:  \n",
    "          \n",
    "        soup = bs(r.text, 'html.parser')\n",
    "\n",
    "        items = soup.select('div.g > h3.r > a')\n",
    "        \n",
    "        if len(items) > 0:\n",
    "            #print(items[0])\n",
    "            s = items[0].get('href')\n",
    "            ms_link = parse_qs(urlparse(s)[4])['q'][0]\n",
    "            \n",
    "            parsed_link = urlparse(ms_link)\n",
    "            \n",
    "            if 'morningstar' not in parsed_link[1]:\n",
    "                return -1\n",
    "            else:                \n",
    "                return parse_qs(urlparse(ms_link)[4])['id'][0]\n",
    "                        \n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert Bloomberg to morningstar ticker\n",
    "\n",
    "def bbg2morningstar(bbg_ticker):\n",
    "    return isin2morningstar(bbg2isin(bbg_ticker))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert ISIN to Financial Times symbol\n",
    "\n",
    "def isin2ft(isin_ticker):\n",
    "    url = 'http://markets.ft.com'\n",
    "    \n",
    "    # Search on financial times\n",
    "    r = requests.get( url + '/data/search', params = {'query':isin_ticker})\n",
    "    \n",
    "    if r.status_code == requests.codes.ok:\n",
    "        soup = bs(r.text, \"html.parser\")\n",
    "        tb = soup.find('table', class_='mod-ui-table mod-ui-table--freeze-pane')      \n",
    "        tr = tb.findAll('tr')\n",
    "                \n",
    "        if len(tr)!= 1:\n",
    "            return\n",
    "        \n",
    "        td = tr[0].find('td')\n",
    "        href = td.find('a').get('href')\n",
    "        name = td.text\n",
    "        \n",
    "        #print(href)\n",
    "        #print(name)\n",
    "        \n",
    "        td = td.find_next_sibling()\n",
    "        symbol = td.text\n",
    "        #print(symbol)\n",
    "    \n",
    "        r = requests.get(url + href)\n",
    "        #print(r.url)\n",
    "        if r.status_code == requests.codes.ok:\n",
    "            soup = bs(r.text, \"html.parser\")\n",
    "            \n",
    "            k = soup.find('section', class_='mod-tearsheet-add-to-watchlist')\n",
    "            js = json.loads(str(k.get('data-mod-config')))\n",
    "            \n",
    "            xid = js['xid']\n",
    "            #print(xid)\n",
    "    \n",
    "            return xid\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAPPAUI:LX\n",
      "LU0270844359\n",
      "F0000003LF\n",
      "28306098\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(isin2bbg('LU0270844359'))\n",
    "    print(bbg2isin('FAPPAUI:LX'))\n",
    "    print(bbg2morningstar('FAPPAUI:LX'))\n",
    "    print(isin2ft('LU0270844359'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
